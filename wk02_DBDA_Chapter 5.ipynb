{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Chapter 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### text: Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Inferential statistical techniques assign precise measures to our uncertainty about possibilities.   \n",
    "Uncertainty is measured in terms of probability, and therefore we must establish the\n",
    "properties of probability before we can make inferences about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 4.1. THE SET OF ALL POSSIBLE EVENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Suppose I have a coin that I am going to flip. How likely is it to come up a head?   \n",
    "How\n",
    "likely is it to come up a tail?  \n",
    "How likely is it to come up a torso?   \n",
    "Notice that when\n",
    "we contemplate the likelihood of each outcome, we have in mind a set of all possible\n",
    "outcomes.   \n",
    "Torso is not one of the possible outcomes.   \n",
    "Notice also that a single flip of a\n",
    "coin can result in only one outcome; it cannot be both heads and tails in a single flip.  \n",
    "The outcomes are mutually exclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Whenever we ask about how likely an outcome is, we always ask with a set of possible\n",
    "outcomes in mind.   \n",
    "This set exhausts all possible outcomes, and the outcomes are all\n",
    "mutually exclusive.   \n",
    "This set is called the **sample space(표본 공간)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Consider the probability that a coin comes up heads when it is flipped.   \n",
    "If the coin is\n",
    "fair, it should come up heads in about 50% of the flips.   \n",
    "If the coin (or its flipping mechanism) is biased, then it will tend to come up heads more than or less than 50% of the\n",
    "flips.   \n",
    "The probability of coming up heads can be denoted with parameter label $\\theta$ (Greek\n",
    "letter theta); for example, a coin is fair when $\\theta$ = 0.5 (spoken “theta equals point five”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We can also consider our **degree of belief** that the coin is fair.   \n",
    "We might know that the coin was manufactured by a government mint(조폐공사), and therefore we have a high degree of belief that the coin is fair.   \n",
    "Alternatively, we might know that the coin was manufactured\n",
    "by Acme Magic and Novelty Company, and therefore we have a high degree of belief\n",
    "that the coin is biased.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**The degree of belief about a parameter can be denoted $p(\\theta)$.**  \n",
    "If the coin was minted by the federal government, we might have a strong belief that the coin is fair; for example we might believe that $p(\\theta=0.5)$ = 0.99, spoken “the probability that theta equals 0.5 is 99 percent.”   \n",
    "If the coin was minted by the Novelty company, we might have a strong belief that the coin is biased; for example we might believe that $p(\\theta=0.5)$ = 0.01 and that $p(\\theta=0.9)$ = 0.99."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Both \"probability\" of head or tail outcome and “degree of belief ” in biases refer to sample spaces.   \n",
    "* The sample space for flips of a coin consists of two possible outcomes:\n",
    "head and tail.  \n",
    "* The sample space for coin bias consists of a continuum of possible values:\n",
    "$\\theta$ = 0.0, $\\theta$ = 0.01, $\\theta$ = 0.02, $\\theta$ = 0.03, and all values in between, up to $\\theta$ = 1.0.**    \n",
    "* When we flip a given coin, we are sampling from the space of head or tail.   \n",
    "* When we grab a coin at random from a sack of coins, in which each coin may have a different bias,we are sampling from the space of possible biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Chapter 5 - Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "On a typical day at your location, what is the probability that it is cloudy?   Suppose you are told it is raining, now what is the probability that it is cloudy?   \n",
    "Notice that\n",
    "those two probabilities are not equal, because we can be pretty sure that $$p(cloudy) <\n",
    "p(cloudy|raining)$$   \n",
    "Suppose instead you are told that everyone outside is wearing\n",
    "sunglasses.   \n",
    "Most likely, it is true that $$p(cloudy) > p(cloudy|sunglasses)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We started with prior credibility allocated\n",
    "over two possible states of the sky: cloudy or sunny.   \n",
    "Then we took into account some\n",
    "other data, namely, that it is raining or that people are wearing sunglasses.   Conditional on the new data, we re-allocated credibility across the possible states of the sky.   \n",
    "When the data indicated rain, then cloudy was more credible than when we started.   \n",
    "When the data\n",
    "instead indicated sunglasses, then cloudy was less credible than when we started.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Bayes’rule is merely the mathematical relation between the prior allocation of credibility and\n",
    "the posterior reallocation of credibility conditional on data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 5.1. BAYES’ RULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Thomas Bayes (1702-1761) was a mathematician and Presbyterian minister in England.  \n",
    "His famous theorem was published posthumously in 1763.  \n",
    "The simple rule has\n",
    "vast ramifications(영향) for statistical inference.\n",
    "\n",
    "There is another branch of statistics, called **frequentist**(빈도주의자), which does not use Bayes’ rule\n",
    "for inference and decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 5.1.1. Derived from definitions of conditional probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ \\large p(c|r)= \\frac{p(r,c)}{p(r)}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large p(c|r)p(r)= p(r,c)$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large p(r|c)p(c)= p(r,c)$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large p(c|r)p(r)=p(r|c)p(c)$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large p(c|r)= \\frac{p(r|c)p(c)}{p(r)}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large p(c|r)= \\frac{p(r|c)p(c)}{\\sum_{c^*} p(r|c^*) p(c^*)}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In Equation 5.6, the $c$ in the numerator is a specific fixed value, whereas the $c^∗$ in the denominator is a variable that takes on all possible values.  \n",
    "\n",
    "**Equations 5.5 and 5.6 are called Bayes’ rule.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 5.1.2. Bayes’ rule intuited from a two-way discrete table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Consider Table 5.1, which shows the joint probabilities of a row attribute and a column\n",
    "attribute, along with their **marginal probabilities(주변확률)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br>\n",
    "<img style=\"float: left;\" src=\"pic3/05_01.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br>\n",
    "<img style=\"float: left;\" src=\"pic3/05_02.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br><br>\n",
    "조건부 확률 $p(hair color|eye color=Blue)$ 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br>\n",
    "<img style=\"float: left;\" src=\"pic3/05_03.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<img style=\"float: left;\" src=\"pic3/05_10.jpg\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Disease Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Consider trying to diagnose a rare disease.   \n",
    "Suppose that in the general population, the\n",
    "probability of having the disease is only one in a thousand.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We denote the true presence\n",
    "or absence of the disease as the value of a parameter, $\\theta$, that can have the value \n",
    "* $\\theta$ = ☹️ if disease is present in a person, \n",
    "* $\\theta$ = 🙂 if the disease is absent.   \n",
    "\n",
    "The base rate of the disease is therefore denoted $p(\\theta =$☹️$)$ = 0.001.  \n",
    "This is our prior belief that a\n",
    "person selected at random has the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Suppose that there is a test for the disease that has a 99% hit rate, which means that if a\n",
    "person has the disease, then the test result is positive 99% of the time.   \n",
    "We denote  as \n",
    "* T = + if a positive test result \n",
    "* T = − if a negative test result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The observed test result is the datum that we will use to modify our belief about the value of the underlying disease\n",
    "parameter.  \n",
    "The hit rate is expressed formally as   \n",
    "$p(T = + | \\theta =$☹️$)$ = 0.99.   \n",
    "\n",
    "Suppose also\n",
    "that the test has a false alarm rate of 5%.   \n",
    "This means that 5% of the time when the disease\n",
    "is absent, the test falsely indicates that the disease is present.   \n",
    "The false alarm rate is expressed formally as   \n",
    "$p(T = + | \\theta =$🙂$)$ = 0.05.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Suppose we sample a person at random from the population, administer the test, and\n",
    "it comes up positive.   \n",
    "What is the posterior probability that the person has the disease?  \n",
    "Mathematically expressed, we are asking,   \n",
    "what is $p(\\theta =$☹️$ | T = + )$?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Before determining\n",
    "the answer from Bayes’ rule, generate an intuitive answer and see if your intuition matches\n",
    "the Bayesian answer.   \n",
    "Most people have an intuition that the probability of having the\n",
    "disease is near the hit rate of the test (which in this case is 99%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br>\n",
    "<img style=\"float: left;\" src=\"pic3/05_04.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Table 5.4 shows how to conceptualize disease diagnosis as a case of Bayes’ rule.  \n",
    "The base rate of the disease is shown in the lower marginal of the table.   \n",
    "Because the background probability of having the disease is $p(\\theta =$☹️$)$ = 0.001, it is the case that the\n",
    "probability of not having the disease is the complement, $p(\\theta =$🙂$)$ = 1 − 0.001 = 0.999.  \n",
    "Without any information about test results, this lower marginal probability is our prior\n",
    "belief about a person having the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large p(\\theta =☹️|T=+)= \\frac{p(T = + | \\theta =☹️) p(\\theta =☹️)}{\\sum_{\\theta} p(T=+|\\theta) p(\\theta)}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large = \\frac{0.99 \\times 0.001}{0.99 \\times 0.001+0.005 \\times (1-0.001)}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large = 0.019$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 5.2. APPLIED TO PARAMETERS AND DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**The key application that makes Bayes’ rule so useful is when the row variable represents\n",
    "data values and the column variable represents parameter values.**   \n",
    "A model of data specifies\n",
    "the probability of particular data values given the model’s structure and parameter values.  \n",
    "The model also indicates the probability of the various parameter values.   \n",
    "In other words, a model specifies  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$p$(data values | parameters values)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;along with the prior, $p$(parameters values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "and we use Bayes’ rule to convert that to what we really want to know, which is how strongly we should believe in the various parameter values, given the data:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$p$(parameters values | data values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br>\n",
    "<img style=\"float: left;\" src=\"pic3/05_05.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The factors of Bayes’ rule have specific names that will be used regularly throughout\n",
    "the book, as indicated here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br>\n",
    "<img style=\"float: left;\" src=\"pic3/05_06.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "where the superscript asterisk in $\\theta^∗$ is merely a reminder that the denominator’s $\\theta^∗$ is\n",
    "distinct from the specific $\\theta$ value in the numerator of Equation 5.7.  \n",
    "* prior, $p(\\theta)$,\n",
    "is the credibility of the $\\theta$ values without the data $D$.   \n",
    "* posterior, $p(\\theta|D)$, is the\n",
    "credibility of $\\theta$ values with the data $D$ taken into account.   \n",
    "* likelihood, $p(D|\\theta)$, is\n",
    "the probability that the data could be generated by the model with parameter value $\\theta$.  \n",
    "* evidence for the model, $p(D)$, is the overall probability of the data according to the model, determined by averaging across all possible parameter values weighted by the strength of belief in those parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The denominator(분모) of Bayes’ rule, labeled in Equation 5.7 as the evidence for the model, is also called the **marginal likelihood**.   \n",
    "The term “evidence”is ambiguous.   \n",
    "The term “marginal likelihood” refers specifically to the\n",
    "operation of taking the average of the likelihood, $p(D|\\theta)$, across all values of $\\theta$, weighted\n",
    "by the prior probability of $\\theta$.   \n",
    "In this book, I will use the terms “evidence” and “marginal\n",
    "likelihood” interchangeably"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Up to this point, Bayes’ rule has been presented only in the context of discrete-valued\n",
    "variables.   \n",
    "It also applies to continuous variables, but probability masses become probability densities and sums become integrals.   \n",
    "For continuous variables, the only change in\n",
    "Bayes’ rule is that the marginal likelihood changes from the sum in Equation 5.8 to an integral:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\large p(D)= \\int p(D|\\theta^*)p(\\theta^*)d\\theta^*$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 5.2.1. Data-order invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Bayes’ rule in Equation 5.7 gets us from a prior belief, $p(\\theta)$, to a posterior belief, $p(\\theta|D)$,\n",
    "when we take into account some data $D$.   \n",
    "Now suppose we observe some more data, which we’ll denote $D'$.   \n",
    "We can then update our beliefs again, from $p(\\theta|D)$ to $p(\\theta|D',D)$.  \n",
    "Here’s the question: Does our final belief depend on whether we update with $D$ first\n",
    "and $D'$ second, or update with $D'$ first and $D$ second?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The answer is: It depends!   \n",
    "In particular, it depends on the model function that defines\n",
    "the likelihood, $p(D|\\theta)$.   \n",
    "In many models, the probability of data, $p(D|\\theta)$, does not depend\n",
    "in any way on other data.   \n",
    "That is, the joint probability  $p(D,D'|\\theta)$ equals $p(D|\\theta)$·$p(D'|\\theta)$.  \n",
    "In other words, in this sort of model, the data probabilities are independent. \n",
    "Under this condition, then the order\n",
    "of updating has no effect of the final posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This invariance to ordering of the data makes sense intuitively: If the likelihood\n",
    "function has no dependence on data ordering, then the posterior shouldn’t have any\n",
    "dependence on data ordering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 5.4. WHY BAYESIAN INFERENCE CAN BE DIFFICULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Determining the posterior distribution directly from Bayes’ rule involves computing the evidence (a.k.a. marginal likelihood) in Equations 5.8 and 5.9.      \n",
    "In the usual case of continuous parameters, the integral in Equation 5.9 can be impossible to solve analytically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Instead of analytical mathematical approaches, another class of methods involves numerical approximation of the integral.   \n",
    "When the parameter space is small, one numerical approximation method is to cover the space with a  grid of points and\n",
    "compute the integral by exhaustively summing across that grid.   \n",
    "This was the approach\n",
    "we used in Figures 5.2 and 5.3, where the domain of the parameter $\\theta$ was represented by a\n",
    "fine comb of values, and the integral across the continuous parameter $\\theta$ was approximated\n",
    "by a sum over the many discrete representative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This method will not work for models with many parameters, however.   \n",
    "In many realistic models, there are dozens\n",
    "or even hundreds of parameters.   \n",
    "If we represent each parameter with a grid\n",
    "of 1,000 values, then for P parameters there are $1,000^P$ combinations of parameter values.   \n",
    "When P is even moderately large, there are far too many combinations for even\n",
    "a modern computer to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Another kind of approximation involves randomly sampling a large number of\n",
    "representative combinations of parameter values from the posterior distribution.   \n",
    "In recent decades, many such algorithms have been developed, generally referred to as Markov chain Monte Carlo (MCMC) methods.   \n",
    "What makes these methods so useful is that they can generate representative parameter-value combinations from the posterior distribution of complex models without computing the integral in Bayes’ rule.   \n",
    "It is the development of these MCMC methods that has allowed Bayesian statistical methods to\n",
    "gain practical use. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
