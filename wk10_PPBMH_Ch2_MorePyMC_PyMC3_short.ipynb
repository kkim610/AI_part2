{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Chapter 2\n",
    "======\n",
    "`Original content created by Cam Davidson-Pilon`\n",
    "\n",
    "`Ported to Python 3 and PyMC3 by Max Margenot (@clean_utensils) and Thomas Wiecki (@twiecki) at Quantopian (@quantopian)`\n",
    "\n",
    "___\n",
    "\n",
    "This chapter introduces more PyMC3 syntax and variables and ways to think about how to model a system from a Bayesian perspective. It also contains tips and data visualization techniques for assessing goodness-of-fit for your Bayesian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "figsize(11, 9)\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## A little more on PyMC3\n",
    "\n",
    "### Model Context\n",
    "\n",
    "In PyMC3, we typically handle all the variables we want in our model within the context of the `Model` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    parameter = pm.Exponential(\"poisson_param\", 1.0)\n",
    "    data_generator = pm.Poisson(\"data_generator\", parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Any variables created within a given `Model`'s context will be automatically assigned to that model. If you try to define a variable outside of the context of a model, you will get an error.\n",
    "\n",
    "We can continue to work within the context of the same model by using `with` with the name of the model object that we have already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    data_plus_one = data_generator + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We can examine the same variables outside of the model context once they have been defined, but to define more variables that the model will recognize they have to be within the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "parameter.tag.test_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Each variable assigned to a model will be defined with its own name, the first string parameter (we will cover this further in the variables section). To create a different model object with the same name as one we have used previously, we need only run the first block of code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    theta = pm.Exponential(\"theta\", 2.0)\n",
    "    data_generator = pm.Poisson(\"data_generator\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We can also define an entirely separate model. Note that we are free to name our models whatever we like, so if we do not want to overwrite an old model we need only make another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as ab_testing:\n",
    "    p_A = pm.Uniform(\"P(A)\", 0, 1)\n",
    "    p_B = pm.Uniform(\"P(B)\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You probably noticed that PyMC3 will often give you notifications about transformations when you add variables to your model. These transformations are done internally by PyMC3 to modify the space that the variable is sampled in (when we get to actually sampling the model). This is an internal feature which helps with the convergence of our samples to the posterior distribution and serves to improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### PyMC3 Variables\n",
    "\n",
    "All PyMC3 variables have an initial value (i.e. test value). Using the same variables from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"parameter.tag.test_value =\", parameter.tag.test_value)\n",
    "print(\"data_generator.tag.test_value =\", data_generator.tag.test_value)\n",
    "print(\"data_plus_one.tag.test_value =\", data_plus_one.tag.test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The `test_value` is used only for the model, as the starting point for sampling if no other start is specified. It will not change as a result of sampling. This initial state can be changed at variable creation by specifying a value for the `testval` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    parameter = pm.Exponential(\"poisson_param\", 1.0, testval=0.5)\n",
    "\n",
    "print(\"parameter.tag.test_value =\", parameter.tag.test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This can be helpful if you are using a more unstable prior that may require a better starting point.\n",
    "\n",
    "PyMC3 is concerned with two types of programming variables: stochastic and deterministic.\n",
    "\n",
    "*  *stochastic variables*(확률변수, random variable) are variables that are not deterministic, i.e., even if you knew all the values of the variables' parameters and components, it would still be random. Included in this category are instances of classes `Poisson`, `DiscreteUniform`, and `Exponential`.\n",
    "\n",
    "*  *deterministic variables*(확정변수?) are variables that are not random if the variables' parameters and components were known. This might be confusing at first: a quick mental check is *if I knew all of variable `foo`'s component variables, I could determine what `foo`'s value is.* \n",
    "\n",
    "We will detail each below.\n",
    "\n",
    "#### Initializing Stochastic variables\n",
    "\n",
    "Initializing a stochastic, or random, variable requires a `name` argument, plus additional parameters that are class specific. For example:\n",
    "\n",
    "`some_variable = pm.DiscreteUniform(\"discrete_uni_var\", 0, 4)`\n",
    "\n",
    "where 0, 4 are the `DiscreteUniform`-specific lower and upper bound on the random variable. The [PyMC3 docs](http://pymc-devs.github.io/pymc3/api.html) contain the specific parameters for stochastic variables. (Or use `??` if you are using IPython!)\n",
    "\n",
    "The `name` attribute is used to retrieve the posterior distribution later in the analysis, so it is best to use a descriptive name. Typically, I use the Python variable's name as the `name`.\n",
    "\n",
    "For multivariable problems, rather than creating a Python array of stochastic variables, addressing the `shape` keyword in the call to a stochastic variable creates multivariate array of (independent) stochastic variables. The array behaves like a NumPy array when used like one, and references to its `tag.test_value` attribute return NumPy arrays.  \n",
    "\n",
    "The `shape` argument also solves the annoying case where you may have many variables $\\beta_i, \\; i = 1,...,N$ you wish to model. Instead of creating arbitrary names and variables for each one, like:\n",
    "\n",
    "    beta_1 = pm.Uniform(\"beta_1\", 0, 1)\n",
    "    beta_2 = pm.Uniform(\"beta_2\", 0, 1)\n",
    "    ...\n",
    "\n",
    "we can instead wrap them into a single variable:\n",
    "\n",
    "    betas = pm.Uniform(\"betas\", 0, 1, shape=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Deterministic variables\n",
    "\n",
    "We can create a deterministic variable similarly to how we create a stochastic variable. We simply call up the `Deterministic` class in PyMC3 and pass in the function that we desire\n",
    "\n",
    "    deterministic_variable = pm.Deterministic(\"deterministic variable\", some_function_of_variables)\n",
    "\n",
    "For all purposes, we can treat the object `some_deterministic_var` as a variable and not a Python function. \n",
    "\n",
    "Calling `pymc3.Deterministic` is the most obvious way, but not the only way, to create deterministic variables. Elementary operations, like addition, exponentials etc. implicitly create deterministic variables. For example, the following returns a deterministic variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", 1.0)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", 1.0)\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=10)\n",
    "\n",
    "new_deterministic_variable = lambda_1 + lambda_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<span style=\"color:red\">If we want a *deterministic* variable to actually be tracked by our sampling, however, we need to define it explicitly as a named *deterministic* variable with the constructor.\n",
    "\n",
    "The use of the `deterministic` variable was seen in the previous chapter's text-message example.  Recall the model for $\\lambda$ looked like: \n",
    "\n",
    "$$\n",
    "\\lambda = \n",
    "\\begin{cases}\\lambda_1  & \\text{if } t \\lt \\tau \\cr\n",
    "\\lambda_2 & \\text{if } t \\ge \\tau\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And in PyMC3 code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_data_points = 5  # in CH1 we had ~70 data points\n",
    "idx = np.arange(n_data_points)\n",
    "with model:\n",
    "    lambda_ = pm.math.switch(tau >= idx, lambda_1, lambda_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Clearly, if $\\tau, \\lambda_1$ and $\\lambda_2$ are known, then $\\lambda$ is known completely, hence it is a deterministic variable. We use the `switch` function here to change from $\\lambda_1$ to $\\lambda_2$ at the appropriate time. This function is directly from the `theano` package, which we will discuss in the next section.\n",
    "\n",
    "Inside a `deterministic` variable, the stochastic variables passed in behave like scalars or NumPy arrays (if multivariable). We can do whatever we want with them as long as the dimensions match up in our calculations.\n",
    "\n",
    "For example, running the following:\n",
    "\n",
    "    def subtract(x, y):\n",
    "        return x - y\n",
    "    \n",
    "    stochastic_1 = pm.Uniform(\"U_1\", 0, 1)\n",
    "    stochastic_2 = pm.Uniform(\"U_2\", 0, 1)\n",
    "    \n",
    "    det_1 = pm.Deterministic(\"Delta\", subtract(stochastic_1, stochastic_2))\n",
    "    \n",
    "Is perfectly valid PyMC3 code. Saying that our expressions behave like NumPy arrays is not exactly honest here, however. The main catch is that the expression that we are making *must* be compatible with `theano` tensors, which we will cover in the next section. Feel free to define whatever functions that you need in order to compose your model. However, if you need to do any array-like calculations that would require NumPy functions, make sure you use their equivalents in `theano`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Theano\n",
    "\n",
    "The majority of the heavy lifting done by PyMC3 is taken care of with the `theano` package. The notation in `theano` is remarkably similar to NumPy. It also supports many of the familiar computational elements of NumPy. However, while NumPy directly executes computations, e.g. when you run `a + b`, `theano` instead builds up a \"compute graph\" that tracks that you want to perform the `+` operation on the elements `a` and `b`. Only when you `eval()` a `theano` expression does the computation take place (i.e. `theano` is lazy evaluated). Once the compute graph is built, we can perform all kinds of mathematical optimizations (e.g. simplifications), compute gradients via autodiff, compile the entire graph to C to run at machine speed, and also compile it to run on the GPU. PyMC3 is basically a collection of `theano` symbolic expressions for various probability distributions that are combined to one big compute graph making up the whole model log probability, and a collection of inference algorithms that use that graph to compute probabilities and gradients. For practical purposes, what this means is that in order to build certain models we sometimes have to use `theano`.\n",
    "\n",
    "Let's write some PyMC3 code that involves `theano` calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import theano.tensor as tt\n",
    "\n",
    "with pm.Model() as theano_test:\n",
    "    p1 = pm.Uniform(\"p\", 0, 1)\n",
    "    p2 = 1 - p1\n",
    "    p = tt.stack([p1, p2])\n",
    "    \n",
    "    assignment = pm.Categorical(\"assignment\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Here we use `theano`'s `stack()` function in the same way we would use one of NumPy's stacking functions: to combine our two separate variables, `p1` and `p2`, into a vector with $2$ elements. The stochastic `categorical` variable does not understand what we mean if we pass a NumPy array of `p1` and `p2` to it because they are both `theano` variables. Stacking them like this combines them into one `theano` variable that we can use as the complementary pair of probabilities for our two categories.\n",
    "\n",
    "Throughout the course of this book we use several `theano` functions to help construct our models. If you have more interest in looking at `theano` itself, be sure to check out the [documentation](http://deeplearning.net/software/theano/library/).\n",
    "\n",
    "After these technical considerations, we can get back to defining our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Including observations in the Model\n",
    "\n",
    "At this point, it may not look like it, but we have fully specified our priors. For example, we can ask and answer questions like \"What does my prior distribution of $\\lambda_1$ look like?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "figsize(12.5, 4)\n",
    "\n",
    "\n",
    "samples = lambda_1.random(size=20000)\n",
    "plt.hist(samples, bins=70, histtype=\"stepfilled\", density=True, stacked=True)\n",
    "\n",
    "plt.title(\"Prior distribution for $\\lambda_1$\")\n",
    "plt.xlim(0, 8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To frame this in the notation of the first chapter, though this is a slight abuse of notation, we have specified $P(A)$. Our next goal is to include data/evidence/observations $X$ into our model. \n",
    "\n",
    "PyMC3 stochastic variables have a keyword argument `observed`. The keyword `observed` has a very simple role: fix the variable's current value to be the given data, typically a NumPy `array` or pandas `DataFrame`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = np.array([10, 5])\n",
    "with model:\n",
    "    fixed_variable = pm.Poisson(\"fxd\", 1, observed=data)\n",
    "print(\"value: \", fixed_variable.tag.test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This is how we include data into our models: initializing a stochastic variable to have a *fixed value*. \n",
    "\n",
    "To complete our text message example, we fix the PyMC3 variable `observations` to the observed dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# We're using some fake data here\n",
    "data = np.array([10, 25, 15, 20, 35])\n",
    "with model:\n",
    "    obs = pm.Poisson(\"obs\", lambda_, observed=data)\n",
    "print(obs.tag.test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Modeling approaches\n",
    "\n",
    "A good starting thought to Bayesian modeling is to think about *how your data might have been generated*. Position yourself in an omniscient position, and try to imagine how *you* would recreate the dataset. \n",
    "\n",
    "In the last chapter we investigated text message data. We begin by asking how our observations may have been generated:\n",
    "\n",
    "1.  We started by thinking \"what is the best random variable to describe this count data?\" A Poisson random variable is a good candidate because it can represent count data. So we model the number of sms's received as sampled from a Poisson distribution.\n",
    "\n",
    "2.  Next, we think, \"Ok, assuming sms's are Poisson-distributed, what do I need for the Poisson distribution?\" Well, the Poisson distribution has a parameter $\\lambda$. \n",
    "\n",
    "3.  Do we know $\\lambda$? No. In fact, we have a suspicion that there are *two* $\\lambda$ values, one for the earlier behaviour and one for the later behaviour. We don't know when the behaviour switches though, but call the switchpoint $\\tau$.\n",
    "\n",
    "4. What is a good distribution for the two $\\lambda$s? The exponential is good, as it assigns probabilities to positive real numbers. Well the exponential distribution has a parameter too, call it $\\alpha$.\n",
    "\n",
    "5.  Do we know what the parameter $\\alpha$ might be? No. At this point, we could continue and assign a distribution to $\\alpha$, but it's better to stop once we reach a set level of ignorance: whereas we have a prior belief about $\\lambda$, (\"it probably changes over time\", \"it's likely between 10 and 30\", etc.), we don't really have any strong beliefs about $\\alpha$. So it's best to stop here. \n",
    "\n",
    "    What is a good value for $\\alpha$ then? We think that the $\\lambda$s are between 10-30, so if we set $\\alpha$ really low (which corresponds to larger probability on high values) we are not reflecting our prior well. Similar, a too-high alpha misses our prior belief as well. A good idea for $\\alpha$ as to reflect our belief is to set the value so that the mean of $\\lambda$, given $\\alpha$, is equal to our observed mean. This was shown in the last chapter.\n",
    "\n",
    "6. We have no expert opinion of when $\\tau$ might have occurred. So we will suppose $\\tau$ is from a discrete uniform distribution over the entire timespan.\n",
    "\n",
    "\n",
    "Below we give a graphical visualization of this, where arrows denote `parent-child` relationships. (provided by the [Daft Python library](http://daft-pgm.org/) )\n",
    "\n",
    "<img src=\"http://i.imgur.com/7J30oCG.png\" width = 700/>\n",
    "\n",
    "\n",
    "PyMC3, and other probabilistic programming languages, have been designed to tell these data-generation *stories*. More generally, B. Cronin writes [5]:\n",
    "\n",
    "> Probabilistic programming will unlock narrative explanations of data, one of the holy grails of business analytics and the unsung hero of scientific persuasion. People think in terms of stories - thus the unreasonable power of the anecdote to drive decision-making, well-founded or not. But existing analytics largely fails to provide this kind of story; instead, numbers seemingly appear out of thin air, with little of the causal context that humans prefer when weighing their options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Same story; different ending.\n",
    "\n",
    "Interestingly, we can create *new datasets* by retelling the story.\n",
    "For example, if we reverse the above steps, we can simulate a possible realization of the dataset.\n",
    "\n",
    "1\\. Specify when the user's behaviour switches by sampling from $\\text{DiscreteUniform}(0, 80)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tau = np.random.randint(0, 80)\n",
    "print(tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "2\\. Draw $\\lambda_1$ and $\\lambda_2$ from an $\\text{Exp}(\\alpha)$ distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "alpha = 1./20.\n",
    "lambda_1, lambda_2 = np.random.exponential(scale=1/alpha, size=2)\n",
    "print(lambda_1, lambda_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "3\\.  For days before $\\tau$, represent the user's received SMS count by sampling from $\\text{Poi}(\\lambda_1)$, and sample from  $\\text{Poi}(\\lambda_2)$ for days after $\\tau$. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = np.r_[stats.poisson.rvs(mu=lambda_1, size=tau), stats.poisson.rvs(mu=lambda_2, size = 80 - tau)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "4\\. Plot the artificial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.bar(np.arange(80), data, color=\"#348ABD\")\n",
    "plt.bar(tau-1, data[tau - 1], color=\"r\", label=\"user behaviour changed\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"count of text-msgs received\")\n",
    "plt.title(\"Artificial dataset\")\n",
    "plt.xlim(0, 80)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "It is okay that our fictional dataset does not look like our observed dataset: the probability is incredibly small it indeed would. PyMC3's engine is designed to find good parameters, $\\lambda_i, \\tau$, that maximize this probability.  \n",
    "\n",
    "\n",
    "The ability to generate artificial dataset is an interesting side effect of our modeling, and we will see that this ability is a very important method of Bayesian inference. We produce a few more datasets below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def plot_artificial_sms_dataset():\n",
    "    tau = stats.randint.rvs(0, 80)\n",
    "    alpha = 1./20.\n",
    "    lambda_1, lambda_2 = stats.expon.rvs(scale=1/alpha, size=2)\n",
    "    data = np.r_[stats.poisson.rvs(mu=lambda_1, size=tau), stats.poisson.rvs(mu=lambda_2, size=80 - tau)]\n",
    "    plt.bar(np.arange(80), data, color=\"#348ABD\")\n",
    "    plt.bar(tau - 1, data[tau-1], color=\"r\", label=\"user behaviour changed\")\n",
    "    plt.xlim(0, 80);\n",
    "\n",
    "figsize(12.5, 5)\n",
    "plt.title(\"More example of artificial datasets\")\n",
    "for i in range(4):\n",
    "    plt.subplot(4, 1, i+1)\n",
    "    plot_artificial_sms_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Later we will see how we use this to make predictions and test the appropriateness of our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Example: Bayesian A/B testing\n",
    "\n",
    "A/B testing is a statistical design pattern for determining the difference of effectiveness between two different treatments. For example, a pharmaceutical company is interested in the effectiveness of drug A vs drug B. The company will test drug A on some fraction of their trials, and drug B on the other fraction (this fraction is often 1/2, but we will relax this assumption). After performing enough trials, the in-house statisticians sift through the data to determine which drug yielded better results. \n",
    "\n",
    "Similarly, front-end web developers are interested in which design of their website yields more sales or some other metric of interest. They will route some fraction of visitors to site A, and the other fraction to site B, and record if the visit yielded a sale or not. The data is recorded (in real-time), and analyzed afterwards. \n",
    "\n",
    "Often, the post-experiment analysis is done using something called a hypothesis test like *difference of means test* or *difference of proportions test*. This involves often misunderstood quantities like a \"Z-score\" and even more confusing \"p-values\" (please don't ask). If you have taken a statistics course, you have probably been taught this technique (though not necessarily *learned* this technique). And if you were like me, you may have felt uncomfortable with their derivation -- good: the Bayesian approach to this problem is much more natural. \n",
    "\n",
    "### A Simple Case\n",
    "\n",
    "As this is a hacker book, we'll continue with the web-dev example. For the moment, we will focus on the analysis of site A only. Assume that there is some true $0 \\lt p_A \\lt 1$ probability that users who, upon shown site A, eventually purchase from the site. This is the true effectiveness of site A. Currently, this quantity is unknown to us. \n",
    "\n",
    "Suppose site A was shown to $N$ people, and $n$ people purchased from the site. One might conclude hastily that $p_A = \\frac{n}{N}$. Unfortunately, the *observed frequency* $\\frac{n}{N}$ does not necessarily equal $p_A$ -- there is a difference between the *observed frequency* and the *true frequency* of an event. The true frequency can be interpreted as the probability of an event occurring. For example, the true frequency of rolling a 1 on a 6-sided die is $\\frac{1}{6}$. Knowing the true frequency of events like:\n",
    "\n",
    "- fraction of users who make purchases, \n",
    "- frequency of social attributes, \n",
    "- percent of internet users with cats etc. \n",
    "\n",
    "are common requests we ask of Nature. Unfortunately, often Nature hides the true frequency from us and we must *infer* it from observed data.\n",
    "\n",
    "The *observed frequency* is then the frequency we observe: say rolling the die 100 times you may observe 20 rolls of 1. The observed frequency, 0.2, differs from the true frequency, $\\frac{1}{6}$. We can use Bayesian statistics to infer probable values of the true frequency using an appropriate prior and observed data.\n",
    "\n",
    "\n",
    "With respect to our A/B example, we are interested in using what we know, $N$ (the total trials administered) and $n$ (the number of conversions), to estimate what $p_A$, the true frequency of buyers, might be. \n",
    "\n",
    "To setup a Bayesian model, we need to assign prior distributions to our unknown quantities. *A priori*, what do we think $p_A$ might be? For this example, we have no strong conviction about $p_A$, so for now, let's assume $p_A$ is uniform over [0,1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "# The parameters are the bounds of the Uniform.\n",
    "with pm.Model() as model:\n",
    "    p = pm.Uniform('p', lower=0, upper=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Had we had stronger beliefs, we could have expressed them in the prior above.\n",
    "\n",
    "For this example, consider $p_A = 0.05$, and $N = 1500$ users shown site A, and we will simulate whether the user made a purchase or not. To simulate this from $N$ trials, we will use a *Bernoulli* distribution: if  $X\\ \\sim \\text{Ber}(p)$, then $X$ is 1 with probability $p$ and 0 with probability $1 - p$. Of course, in practice we do not know $p_A$, but we will use it here to simulate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#set constants\n",
    "p_true = 0.05  # remember, this is unknown.\n",
    "N = 1500\n",
    "\n",
    "# sample N Bernoulli random variables from Ber(0.05).\n",
    "# each random variable has a 0.05 chance of being a 1.\n",
    "# this is the data-generation step\n",
    "occurrences = stats.bernoulli.rvs(p_true, size=N)\n",
    "\n",
    "print(occurrences) # Remember: Python treats True == 1, and False == 0\n",
    "print(np.sum(occurrences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The observed frequency is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Occurrences.mean is equal to n/N.\n",
    "print(\"What is the observed frequency in Group A? %.4f\" % np.mean(occurrences))\n",
    "print(\"Does this equal the true frequency? %s\" % (np.mean(occurrences) == p_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We combine the observations into the PyMC3 `observed` variable, and run our inference algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#include the observations, which are Bernoulli\n",
    "with model:\n",
    "    obs = pm.Bernoulli(\"obs\", p, observed=occurrences)\n",
    "    # To be explained in chapter 3\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(18000, step=step)\n",
    "    burned_trace = trace[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We plot the posterior distribution of the unknown $p_A$ below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "figsize(12.5, 4)\n",
    "plt.title(\"Posterior distribution of $p_A$, the true effectiveness of site A\")\n",
    "plt.vlines(p_true, 0, 90, linestyle=\"--\", label=\"true $p_A$ (unknown)\")\n",
    "plt.hist(burned_trace[\"p\"], bins=25, histtype=\"stepfilled\", density=True, stacked=True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Our posterior distribution puts most weight near the true value of $p_A$, but also some weights in the tails. This is a measure of how uncertain we should be, given our observations. Try changing the number of observations, `N`, and observe how the posterior distribution changes.\n",
    "\n",
    "### *A* and *B* Together\n",
    "\n",
    "A similar analysis can be done for site B's response data to determine the analogous $p_B$. But what we are really interested in is the *difference* between $p_A$ and $p_B$. Let's infer $p_A$, $p_B$, *and* $\\text{delta} = p_A - p_B$, all at once. We can do this using PyMC3's deterministic variables. (We'll assume for this exercise that $p_B = 0.04$, so $\\text{delta} = 0.01$, $N_B = 750$ (significantly less than $N_A$) and we will simulate site B's data like we did for site A's data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "figsize(12, 4)\n",
    "\n",
    "#these two quantities are unknown to us.\n",
    "true_p_A = 0.05\n",
    "true_p_B = 0.04\n",
    "\n",
    "#notice the unequal sample sizes -- no problem in Bayesian analysis.\n",
    "N_A = 1500\n",
    "N_B = 750\n",
    "\n",
    "#generate some observations\n",
    "observations_A = stats.bernoulli.rvs(true_p_A, size=N_A)\n",
    "observations_B = stats.bernoulli.rvs(true_p_B, size=N_B)\n",
    "print(\"Obs from Site A: \", observations_A[:30], \"...\")\n",
    "print(\"Obs from Site B: \", observations_B[:30], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(np.mean(observations_A))\n",
    "print(np.mean(observations_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Set up the pymc3 model. Again assume Uniform priors for p_A and p_B.\n",
    "with pm.Model() as model:\n",
    "    p_A = pm.Uniform(\"p_A\", 0, 1)\n",
    "    p_B = pm.Uniform(\"p_B\", 0, 1)\n",
    "    \n",
    "    # Define the deterministic delta function. This is our unknown of interest.\n",
    "    delta = pm.Deterministic(\"delta\", p_A - p_B)\n",
    "\n",
    "    \n",
    "    # Set of observations, in this case we have two observation datasets.\n",
    "    obs_A = pm.Bernoulli(\"obs_A\", p_A, observed=observations_A)\n",
    "    obs_B = pm.Bernoulli(\"obs_B\", p_B, observed=observations_B)\n",
    "\n",
    "    # To be explained in chapter 3.\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(20000, step=step)\n",
    "    burned_trace=trace[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Below we plot the posterior distributions for the three unknowns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "p_A_samples = burned_trace[\"p_A\"]\n",
    "p_B_samples = burned_trace[\"p_B\"]\n",
    "delta_samples = burned_trace[\"delta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "figsize(12.5, 10)\n",
    "\n",
    "#histogram of posteriors\n",
    "\n",
    "ax = plt.subplot(311)\n",
    "\n",
    "plt.xlim(0, .1)\n",
    "plt.hist(p_A_samples, histtype='stepfilled', bins=25, alpha=0.85,\n",
    "         label=\"posterior of $p_A$\", color=\"#A60628\", density=True, stacked=True)\n",
    "plt.vlines(true_p_A, 0, 80, linestyle=\"--\", label=\"true $p_A$ (unknown)\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Posterior distributions of $p_A$, $p_B$, and delta unknowns\")\n",
    "\n",
    "ax = plt.subplot(312)\n",
    "\n",
    "plt.xlim(0, .1)\n",
    "plt.hist(p_B_samples, histtype='stepfilled', bins=25, alpha=0.85,\n",
    "         label=\"posterior of $p_B$\", color=\"#467821\", density=True, stacked=True)\n",
    "plt.vlines(true_p_B, 0, 80, linestyle=\"--\", label=\"true $p_B$ (unknown)\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "ax = plt.subplot(313)\n",
    "plt.hist(delta_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label=\"posterior of delta\", color=\"#7A68A6\", density=True, stacked=True)\n",
    "plt.vlines(true_p_A - true_p_B, 0, 60, linestyle=\"--\",\n",
    "           label=\"true delta (unknown)\")\n",
    "plt.vlines(0, 0, 60, color=\"black\", alpha=0.2)\n",
    "plt.legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Notice that as a result of `N_B < N_A`, i.e. we have less data from site B, our posterior distribution of $p_B$ is fatter, implying we are less certain about the true value of $p_B$ than we are of $p_A$.  \n",
    "\n",
    "With respect to the posterior distribution of $\\text{delta}$, we can see that the majority of the distribution is above $\\text{delta}=0$, implying there site A's response is likely better than site B's response. The probability this inference is incorrect is easily computable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Count the number of samples less than 0, i.e. the area under the curve\n",
    "# before 0, represent the probability that site A is worse than site B.\n",
    "print(\"Probability site A is WORSE than site B: %.3f\" % \\\n",
    "    np.mean(delta_samples < 0))\n",
    "\n",
    "print(\"Probability site A is BETTER than site B: %.3f\" % \\\n",
    "    np.mean(delta_samples > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<span style=\"color:red\">If this probability is too high for comfortable decision-making, we can perform more trials on site B (as site B has less samples to begin with, each additional data point for site B contributes more inferential \"power\" than each additional data point for site A). \n",
    "\n",
    "Try playing with the parameters `true_p_A`, `true_p_B`, `N_A`, and `N_B`, to see what the posterior of $\\text{delta}$ looks like. Notice in all this, the difference in sample sizes between site A and site B was never mentioned: it naturally fits into Bayesian analysis.\n",
    "\n",
    "I hope the readers feel this style of A/B testing is more natural than hypothesis testing, which has probably confused more than helped practitioners. Later in this book, we will see two extensions of this model: the first to help dynamically adjust for bad sites, and the second will improve the speed of this computation by reducing the analysis to a single equation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
